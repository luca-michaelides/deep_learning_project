# Deep Learning Project

This repository contains experiments, scripts, and supporting code for working with **large language models (LLMs)**, with a particular focus on **LLaMA‚Äë2** and related attack / analysis workflows.

The project is structured to be:

* reproducible,
* explicit about model downloads and licensing,
* safe for GitHub (large model weights are *not* committed), and
* easy to extend for research and experimentation.

---

## üìÅ Repository Structure

```text
deep_learning_project/
‚îÇ
‚îú‚îÄ‚îÄ llm-attacks/                 # Core codebase for LLM attacks & experiments
‚îÇ   ‚îú‚îÄ‚îÄ api_experiments/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ experiments/
‚îÇ   ‚îú‚îÄ‚îÄ llm_attacks/
‚îÇ   ‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ demo.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ setup.py
‚îÇ
‚îú‚îÄ‚îÄ models/                      # Local model storage (gitignored)
‚îÇ   ‚îî‚îÄ‚îÄ llama2-7b-chat-hf/       # Downloaded LLaMA‚Äë2 model files
‚îÇ
‚îú‚îÄ‚îÄ scripts/                     # Project-level utility scripts
‚îÇ   ‚îî‚îÄ‚îÄ download_llama2.py       # Downloads LLaMA‚Äë2 via Hugging Face
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md                    # This file
```

> **Note**: The `models/` directory is intentionally excluded from version control.

---

## üß† Models

This project currently uses **LLaMA‚Äë2‚Äë7B‚ÄëChat (HF format)**.

* Source: `meta-llama/Llama-2-7b-chat-hf`
* License: Meta LLaMA‚Äë2 Community License

You **must**:

1. Have a Hugging Face account
2. Accept the LLaMA‚Äë2 license on Hugging Face

Model weights are downloaded locally and **never committed to GitHub**.

---

## ‚¨áÔ∏è Downloading LLaMA‚Äë2

A helper script is provided to download the model snapshot locally.

### 1Ô∏è‚É£ Set up environment

```bash
pip install -U transformers huggingface_hub torch accelerate
```

Log in to Hugging Face:

```bash
huggingface-cli login
```

### 2Ô∏è‚É£ Download the model

From the repository root:

```bash
python scripts/download_llama2.py
```

After completion, the model will be available at:

```text
models/llama2-7b-chat-hf/
```

---

## üöÄ Loading the Model (Offline)

Once downloaded, the model can be loaded entirely offline using `transformers`:

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

MODEL_PATH = "./models/llama2-7b-chat-hf"

tokenizer = AutoTokenizer.from_pretrained(
    MODEL_PATH,
    local_files_only=True
)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_PATH,
    local_files_only=True,
    device_map="auto",  # or "cpu"
    torch_dtype="auto"
)
```

---

## ‚ö†Ô∏è Git & Large Files

Model weights are **not tracked** by Git.

Ensure the following is present in `.gitignore`:

```gitignore
models/
```

This keeps the repository lightweight and avoids pushing large binaries or licensed artifacts.

---

## üß™ Experiments & Attacks

The `llm-attacks/` directory contains:

* prompt- and API-based experiments
* attack implementations
* datasets and experiment outputs
* notebooks for exploratory analysis

Refer to `llm-attacks/README.md` for details on specific experiments and usage.

---

## üñ•Ô∏è Hardware Notes

* **CPU-only** loading is supported (slow, high RAM usage)
* **GPU** recommended for inference
* 4‚Äëbit / 8‚Äëbit quantization supported via `bitsandbytes`

Example (4‚Äëbit):

```python
model = AutoModelForCausalLM.from_pretrained(
    MODEL_PATH,
    load_in_4bit=True,
    device_map="auto"
)
```

---

## üìå Reproducibility

To reproduce results:

1. Clone this repository
2. Set up the Python environment
3. Download the model using the provided script
4. Run experiments from `llm-attacks/`

All non-determinism is isolated to model inference where applicable.

---

## üìú License

This repository contains **code only**.

* Code: MIT (unless otherwise specified)
* Models: governed by their respective licenses (e.g. LLaMA‚Äë2 license)

You are responsible for complying with model licensing terms.

---

## ‚ú® Notes

* This repo intentionally avoids Git submodules for simplicity
* Model downloads are explicit and script-driven
* Structure is designed for research and experimentation, not production deployment

---

If you plan to extend this project (new models, attacks, or benchmarks), consider adding:

* a `Makefile`
* experiment configuration files
* structured logging and result tracking
